{
 "cells": [
  {
   "cell_type": "raw",
   "id": "083491d0",
   "metadata": {},
   "source": [
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f321919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmql\n",
    "from enum import Enum\n",
    "import inspect\n",
    "import textwrap\n",
    "import asyncio\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import (\n",
    "    Any,\n",
    "    Union,\n",
    "    ClassVar,\n",
    "    Dict,\n",
    "    Generator,\n",
    "    List,\n",
    "    Optional,\n",
    "    Protocol,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    Optional,\n",
    "    TypeVar,\n",
    "    Callable,\n",
    "    AsyncGenerator,\n",
    "    TypedDict,\n",
    "    Generic,\n",
    "    Coroutine,\n",
    "    Set,\n",
    ")\n",
    "from getpass import getpass\n",
    "from itertools import chain\n",
    "from uuid import UUID, uuid4\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "DJ_URL = f\"http://localhost:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(1)\n",
    "def get_chroma():\n",
    "    return chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VectorStore:\n",
    "    collection_name: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name=\"all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        self.client = get_chroma()\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            self.collection_name, embedding_function=ef\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae62c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_json = requests.get(\n",
    "    f\"{DJ_URL}/metrics\",\n",
    ").json()\n",
    "\n",
    "metrics = pd.DataFrame(metrics_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fcd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = set(d.split(\".\")[0] for d in metrics.dimensions.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd51a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    requests.get(\n",
    "        f\"{DJ_URL}/nodes/{d}\",\n",
    "    ).json()\n",
    "    for d in dimensions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fee974",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = pd.DataFrame(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d642b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions_metrics = {}\n",
    "for m, ds in zip(\n",
    "    metrics.name,\n",
    "    metrics.dimensions.apply(lambda l: {d.split(\".\")[0] for d in l}).tolist(),\n",
    "):\n",
    "    for d in ds:\n",
    "        dimensions_metrics[d] = dimensions_metrics.get(d, [])\n",
    "        dimensions_metrics[d].append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions[\"metrics\"] = dimensions.name.map(dimensions_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8f9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_vectorstore = VectorStore(collection_name=\"metrics\")\n",
    "dimensions_vectorstore = VectorStore(collection_name=\"dimensions\")\n",
    "knowledge_vectorstore = VectorStore(collection_name=\"knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_document(\n",
    "    file_name: str, document_text: str, window_size: int = 200, overlap: int = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a document into overlapping windows of fixed size.\n",
    "\n",
    "    Args:\n",
    "        document (str): The document to split.\n",
    "        window_size (int): The word size of each window.\n",
    "        overlap (int): The amount of word overlap between adjacent windows.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of overlapping windows.\n",
    "    \"\"\"\n",
    "\n",
    "    document = re.split(r\"\\s+\", document_text)\n",
    "    title = (\n",
    "        re.split(r\"[._-]+\", file_name)\n",
    "        + re.split(r\"\\s+\", document_text.split(\"\\n\")[0])[:10]\n",
    "    )\n",
    "    windows = []\n",
    "    start = 0\n",
    "    end = window_size\n",
    "    while end <= len(document):\n",
    "        windows.append(\" \".join((title if start != 0 else []) + document[start:end]))\n",
    "        start += window_size - overlap\n",
    "        end += window_size - overlap\n",
    "    if end > len(document) and start < len(document):\n",
    "        windows.append(\" \".join(title + document[start:]))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_files = glob(\"../examples/knowledge/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_doc_texts = {}\n",
    "for kd in knowledge_files:\n",
    "    with open(kd) as f:\n",
    "        knowledge_doc_texts[\".\".join(Path(kd).name.split(\".\")[:-1])] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_docs = []\n",
    "for kd, doc in knowledge_doc_texts.items():\n",
    "    for idx, passage in enumerate(window_document(kd, doc)):\n",
    "        knowledge_docs.append(\n",
    "            {\n",
    "                \"ids\": kd + f\"_{idx}\",\n",
    "                \"documents\": passage,\n",
    "                \"metadatas\": {\"file\": kd, \"part\": idx},\n",
    "            }\n",
    "        )\n",
    "knowledge_docs = pd.DataFrame(knowledge_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1992a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_vectorstore.collection.add(**knowledge_docs.to_dict(orient=\"list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475832c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_docs = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"ids\": str(m.id),\n",
    "            \"documents\": m.description,\n",
    "            \"metadatas\": {\n",
    "                \"name\": m[\"name\"],\n",
    "                \"query\": m.query,\n",
    "                \"dimensions\": str(m.dimensions),\n",
    "            },\n",
    "        }\n",
    "        for _, m in metrics.iterrows()\n",
    "    ]\n",
    ")\n",
    "\n",
    "metrics_vectorstore.collection.add(**metric_docs.to_dict(orient=\"list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5419445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_docs = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"ids\": str(d.node_revision_id),\n",
    "            \"documents\": d.description,\n",
    "            \"metadatas\": {\n",
    "                \"name\": d[\"name\"],\n",
    "                \"query\": d.query,\n",
    "                \"metrics\": str(d.metrics),\n",
    "            },\n",
    "        }\n",
    "        for _, d in dimensions.iterrows()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dimensions_vectorstore.collection.add(**metric_docs.to_dict(orient=\"list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATCH = {}\n",
    "\n",
    "try:\n",
    "    getsourcelines\n",
    "except NameError:\n",
    "    getsourcelines = inspect.getsourcelines\n",
    "\n",
    "\n",
    "def monkey_patch_getsourcelines(object):\n",
    "    if object in SOURCE_PATCH:\n",
    "        return SOURCE_PATCH[object].splitlines(keepends=True), 0\n",
    "    return getsourcelines(object)\n",
    "\n",
    "\n",
    "inspect.getsourcelines = monkey_patch_getsourcelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def required_value(message: str, return_type: Type[T]) -> Callable[[], T]:\n",
    "    def raise_message() -> T:\n",
    "        raise ValueError(message)\n",
    "\n",
    "    return raise_message\n",
    "\n",
    "\n",
    "class Stringable(Protocol):\n",
    "    def __str__(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "SchemaDict = Dict[str, Union[Type[str], Type[int], \"SchemaDict\"]]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolSchema:\n",
    "    \"\"\"\n",
    "    Final answer value produced from an agent\n",
    "    \"\"\"\n",
    "\n",
    "    schema_dict: TypedDict\n",
    "    _compiled: bool = field(init=False, default=False)\n",
    "    _body: Optional[str] = field(init=False, default=None)\n",
    "    _where: bool = field(init=False, default=False)\n",
    "\n",
    "    @property\n",
    "    def body(self):\n",
    "        self._compile()\n",
    "        return self._body\n",
    "\n",
    "    @property\n",
    "    def code(self):\n",
    "        self._compile()\n",
    "        return (\n",
    "            self.body.replace('\\\\\"[', \"\")\n",
    "            .replace(\"]\", \"\")\n",
    "            .replace('\\\\\"', '\"')\n",
    "            .strip()[1:-1]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def where(self):\n",
    "        self._compile()\n",
    "        return self._where\n",
    "\n",
    "    def _compile(self):\n",
    "        if self._compiled:\n",
    "            return\n",
    "        schema_dict = self.schema_dict.__annotations__\n",
    "        if not schema_dict:\n",
    "            self._body = \"\"\n",
    "            self._where = \"\"\n",
    "            return\n",
    "        where = []\n",
    "        code = []\n",
    "        prefix = self.schema_dict.__name__ + \"_\"\n",
    "\n",
    "        def _helper(schema, key, end=False):\n",
    "            if schema == int:\n",
    "                variable = (prefix + key).upper()\n",
    "                where.append(f'INT({variable}) and STOPS_AT({variable}, \",\")')\n",
    "                return variable\n",
    "            if schema == str:\n",
    "                variable = (prefix + key).upper()\n",
    "                where.append(f\"\"\"STOPS_AT({variable}, '\"')\"\"\")\n",
    "                return variable\n",
    "            if not isinstance(schema, dict):\n",
    "                raise Exception(f\"Unnacceptable type in schema: `{schema}`\")\n",
    "            result = \"{{\"\n",
    "            for idx, (key, value) in enumerate(schema.items()):\n",
    "                if \"[\" in key or \"]\" in key:\n",
    "                    raise Exception(\"schema keys cannot have `[` or `]`\")\n",
    "                variable = _helper(value, key=key, end=idx == len(schema))\n",
    "                quote = '\\\\\"' if value == str else \"\"\n",
    "                result += f'\\\\\"{key}\\\\\": {quote}[{variable}], '\n",
    "            result = result[:-2] + \"}}\"\n",
    "            return result\n",
    "\n",
    "        self._body = _helper(schema_dict, key=\"\")\n",
    "        self._where = \" and \".join(where)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tool:\n",
    "    default_description: ClassVar[str]\n",
    "    default_ref_name: ClassVar[str]\n",
    "    input_schema: ClassVar[ToolSchema]\n",
    "    model_identifier: Optional[str] = None\n",
    "    description_: Optional[str] = None\n",
    "    ref_name_: Optional[str] = None\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        return self.description_ or self.default_description\n",
    "\n",
    "    @property\n",
    "    def ref_name(self):\n",
    "        return self.ref_name_ or self.default_ref_name\n",
    "\n",
    "    async def __call__(self, input: dict) -> \"Observation\":\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Utterance:\n",
    "    utterance_: Stringable\n",
    "    marker: str = \"\"\n",
    "    timestamp: datetime = field(default_factory=datetime.utcnow)\n",
    "    context: str = \"\"\n",
    "    parent_: Optional[\"Utterance\"] = None\n",
    "    utterance_id: UUID = field(default_factory=uuid4)\n",
    "    session_: Optional[\"Session\"] = field(default=None, init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.session = self.parent_.session\n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        return self._parent\n",
    "\n",
    "    @parent.setter\n",
    "    def parent(self, parent: \"Utterance\"):\n",
    "        self.session = parent.session\n",
    "        self.parent_ = parent\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.marker + self.utterance\n",
    "\n",
    "    def history(self, n: Optional[int] = None) -> Generator:\n",
    "        n_ = n or float(\"inf\")\n",
    "        curr = self\n",
    "        while n_ > 0 and (curr is not None):\n",
    "            yield curr\n",
    "            curr = curr.parent\n",
    "            n_ -= 1\n",
    "\n",
    "    @property\n",
    "    def session(self):\n",
    "        if self.session_ is not None:\n",
    "            return self.session_\n",
    "        if self.parent is not None:\n",
    "            return self.parent.session\n",
    "        return None\n",
    "\n",
    "    @session.setter\n",
    "    def session(self, session: \"Session\"):\n",
    "        self.session_ = session\n",
    "\n",
    "    @property\n",
    "    def utterance(self):\n",
    "        return str(self.utterance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class User(Utterance):\n",
    "    \"\"\"\n",
    "    Utterance from a user\n",
    "    \"\"\"\n",
    "\n",
    "    marker = \"User: \"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Observation(Utterance):\n",
    "    \"\"\"\n",
    "    Value produced from a tool\n",
    "    \"\"\"\n",
    "\n",
    "    marker = \"Observation: \"\n",
    "    tool: Tool = field(\n",
    "        default_factory=required_value(\"`tool` is required for an Observation.\", Tool)\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Thought(Utterance):\n",
    "    \"\"\"\n",
    "    Value produced from an agent\n",
    "    \"\"\"\n",
    "\n",
    "    agent: \"Agent\" = field(\n",
    "        default_factory=required_value(\n",
    "            \"`agent` is required for a Thought.\", lambda: Agent()\n",
    "        )\n",
    "    )\n",
    "    marker = \"Thought: \"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Answer(Utterance):\n",
    "    \"\"\"\n",
    "    Final answer value produced from an agent\n",
    "    \"\"\"\n",
    "\n",
    "    agent: \"Agent\" = field(\n",
    "        default_factory=required_value(\n",
    "            \"`agent` is required for a Answer.\", lambda: Agent()\n",
    "        )\n",
    "    )\n",
    "    marker = \"Answer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3df884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionStatus(Enum):\n",
    "    DISCONNECTED = \"DISCONNECTED\"\n",
    "    LIVE = \"LIVE\"\n",
    "    TIMEOUT = \"TIMEOUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Session:\n",
    "    agent: \"Agent\"  # sessions are with an agent\n",
    "    agent_utterances: Set[\n",
    "        Union[Type[Observation], Type[Thought], Type[Answer]]\n",
    "    ] = field(\n",
    "        default_factory=lambda: {Answer}\n",
    "    )  # this determines how verbose the agent will be\n",
    "    session_id: UUID = field(default_factory=uuid4)\n",
    "    status: SessionStatus = SessionStatus.LIVE\n",
    "    utterance: Optional[str] = field(default=None, init=False)\n",
    "    timestamp: datetime = field(default_factory=datetime.utcnow)\n",
    "    timeout: int = 60 * 10\n",
    "    sessions: ClassVar[Dict[UUID, \"Session\"]] = {}\n",
    "\n",
    "    def __post_init__(self):\n",
    "        Session.sessions[self.session_id] = self\n",
    "\n",
    "    async def check_quit(self, utterance: Utterance) -> bool:\n",
    "        if utterance is None or utterance.utterance.strip() in (\"\", \"quit\", \"exit\"):\n",
    "            self.status = SessionStatus.DISCONNECTED\n",
    "            await agent.asend(None)  # tell the agent it's done\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    async def __aiter__(self):\n",
    "        agent_channel = self.agent()\n",
    "\n",
    "        async def session_loop() -> AsyncGenerator[Utterance, Optional[Utterance]]:\n",
    "            while True:\n",
    "                # wait for user input\n",
    "                user: User = yield\n",
    "                # session is disconnected if a user utterance is none or empty\n",
    "                if await self.check_quit(user):\n",
    "                    return\n",
    "                user.session = self\n",
    "                self.utterance = user\n",
    "                # await the agent's response being an answer\n",
    "                # agent response might not be an answer if it is replying verbosely\n",
    "                while not isinstance(self.utterance, Answer):\n",
    "                    response: Union[\n",
    "                        Observation, Thought, Answer\n",
    "                    ] = await agent_channel.asend(self.utterance)\n",
    "                    if await self.check_quit(response):\n",
    "                        return\n",
    "                    self.utterance = response\n",
    "\n",
    "        return session_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VectorStoreMemory:\n",
    "    utterance: Optional[Utterance] = None\n",
    "    vector_store: Optional[VectorStore] = None\n",
    "    default_k: int = 3\n",
    "\n",
    "    @property\n",
    "    def session_id(self) -> Optional[UUID]:\n",
    "        return self.utterance and self.utterance.session_id\n",
    "\n",
    "    async def add_memories(self, utterances: List[Utterance]):\n",
    "        for utterance in utterances:\n",
    "            if self.session_id is not None and utterance.session_id != self.session_id:\n",
    "                raise Exception(\"utterances belong to the same session as this memory!\")\n",
    "        if self.vector_store is None:\n",
    "            self.vector_store = Chroma(str(self.session_id))\n",
    "        await self.vector_store.coll\n",
    "\n",
    "    async def search(self, query: str, k: Optional[int] = None):\n",
    "        k = k or self.default_k\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Agent:\n",
    "    description: str\n",
    "    ref_name: str\n",
    "    query: Callable[[\"Agent\", Any, ...], Coroutine[Any, Any, Utterance]]\n",
    "    tools: List[Type[Tool]]\n",
    "    model_identifier: str\n",
    "    memory: Optional[VectorStoreMemory] = None\n",
    "    _run: Callable[[Any, ...], Coroutine[Any, Any, Utterance]] = field(\n",
    "        default=None, init=False\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.tools, \"This agent requires some tools\"\n",
    "\n",
    "    async def __call__(self, session: Session) -> Utterance:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def run(self, *args, **kwargs):\n",
    "        if self._run is None:\n",
    "            self._run = self._compile_query(self.query)\n",
    "        return await self._run(*args, **kwargs)\n",
    "\n",
    "    def _compile_query(\n",
    "        self, f: Callable[[\"Agent\", Any, ...], Coroutine[Any, Any, Utterance]]\n",
    "    ):\n",
    "        sig = inspect.signature(f)\n",
    "        assert (\n",
    "            next(sig.parameters.values()) == \"agent\"\n",
    "        ), \"first parameter to query must be `agent`\"\n",
    "        source = (\n",
    "            \"async def _f\"\n",
    "            + str(sig)\n",
    "            + \":\\n\"\n",
    "            + (\"    '''\" + f.__doc__.format(**self.__dict__) + \"\\n    '''\")\n",
    "        )\n",
    "        exec(source)\n",
    "        SOURCE_PATCH[locals().get(\"_f\")] = source\n",
    "        f = lmql.query(locals().get(\"_f\"))\n",
    "\n",
    "        async def awrapper(*args, **kwargs):\n",
    "            return (await f(self, *args, **kwargs))[0]\n",
    "\n",
    "        return awrapper\n",
    "\n",
    "    async def __call__(\n",
    "        self, utterances: Set[Union[Type[Observation], Type[Thought], Type[Answer]]]\n",
    "    ) -> AsyncGenerator[Optional[Utterance], Utterance]:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97225a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class KnowledgeSearchTool(Tool):\n",
    "    default_description = \"Search for knowledge documents.\"\n",
    "    default_ref_name = \"knowledge_search\"\n",
    "    input_schema = ToolSchema(TypedDict(\"KnowledgeQuery\", {\"query\": str}))\n",
    "    n_docs: int = 3\n",
    "    threshold: float = 0.0\n",
    "\n",
    "    async def __call__(self, input) -> Observation:\n",
    "        query = input[\"query\"]\n",
    "        results = knowledge_vectorstore.collection.query(\n",
    "            query_texts=query, n_results=self.n_docs\n",
    "        )\n",
    "        res = \"\"\n",
    "        for meta, doc in zip(results[\"metadatas\"], results[\"documents\"]):\n",
    "            res += f\"{meta}: {doc}\\n\"\n",
    "        return Observation(tool=self, utterance=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35107e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def standard_query(agent, convo: str):\n",
    "    '''\n",
    "    argmax\n",
    "        \"\"\"\n",
    "        The following is a conversation between a User and an AI Agent.\n",
    "        The Agent is talkative and provides lots of specific details from its context.\n",
    "        The Agent has Thoughts, uses Tools by providing Tool Input, and ultimately provides Answers.\n",
    "        If the Agent cannot a question using its tools, it truthfully says it does not know.\n",
    "        The Agent uses thoughful reasoning like so:\n",
    "\n",
    "        Thought: use tool\n",
    "        Tool: agent selects appropriate tool\n",
    "        Tool Input: thoroughly descriptive input for the tool to work\n",
    "        ===\n",
    "        Thought: final answer\n",
    "        Answer: agent describes the answer\n",
    "        ===\n",
    "        Thought: no answer\n",
    "        Answer: Agent explains why it could not find an answer\n",
    "\n",
    "        {tools_prompt}\n",
    "\n",
    "        Conversation:\n",
    "        {{convo}}\n",
    "        \"\"\"\n",
    "        \"Thought: [THOUGHT]\\\\n\"\n",
    "        thought = Thought(utterance = THOUGHT, agent = agent, parent = utterance)\n",
    "        if THOUGHT == 'use tool':\n",
    "            \"Tool: [TOOL]\\\\n\"\n",
    "            {tool_body}\n",
    "            observation.parent = thought\n",
    "            return observation\n",
    "        elif THOUGHT == 'final answer':\n",
    "            \"Answer: [ANSWER]\\\\n\"\n",
    "            return Answer(utterance = ANSWER, agent = agent)\n",
    "\n",
    "        else:\n",
    "            return Answer(utterance = \"I cannot find an answer.\", agent = agent)\n",
    "    from\n",
    "        \"{model_identifier}\"\n",
    "    where\n",
    "        THOUGHT in [\"use tool\", \"final answer\", \"no answer\"] and\n",
    "        TOOL in {tool_names} and\n",
    "        STOPS_AT(THOUGHT, \"\\\\n\") and\n",
    "        STOPS_AT(TOOL, \"\\\\n\") and\n",
    "        {tool_conditions}\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardAgent(Agent):\n",
    "    \"A standard agent that can answer queries and solve tasks with tools.\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        description: str = \"\",\n",
    "        ref_name: str = \"standard\",\n",
    "        query=standard_query,\n",
    "        history_length: int = 3,\n",
    "        history_utterances: Set[Type[Utterance]] = {User, Answer},\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            query=query,\n",
    "            description=description or StandardAgent.__doc__,\n",
    "            ref_name=ref_name,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.tools_prompt = \"Here are the tools you choose from:\\n\" + \"\\n\".join(\n",
    "            f\"            {tool.ref_name}: {tool.description}\" for tool in self.tools\n",
    "        )\n",
    "        self.tool_refs = {tool.ref_name: tool for tool in self.tools}\n",
    "        tool_body = []\n",
    "        for tool in self.tools:\n",
    "            tool_body.append(f\"if TOOL=='{tool.ref_name}':\")\n",
    "            tool_body.append(f'                \"Tool Input: {tool.input_schema.body}\"')\n",
    "            tool_body.append(f\"                input_dict = {tool.input_schema.code}\")\n",
    "            tool_body.append(\n",
    "                f\"                observation = await agent.tool_refs.get(TOOL)(input_dict)\"\n",
    "            )\n",
    "        self.tool_body = \"\\n\".join(tool_body)\n",
    "        self.tool_conditions = \" and\\n\".join(\n",
    "            tool.input_schema.where for tool in self.tools\n",
    "        )\n",
    "        self.tool_names = list(self.tool_refs.keys())\n",
    "\n",
    "    async def __call__(\n",
    "        self, utterances: Set[Union[Type[Observation], Type[Thought], Type[Answer]]]\n",
    "    ) -> AsyncGenerator[Optional[Utterance], Optional[Utterance]]:\n",
    "        utterance = yield\n",
    "        # when we send the agent a None it ends\n",
    "        if utterance is None:\n",
    "            return\n",
    "\n",
    "        history = []\n",
    "        for utterance in utterance.history():\n",
    "            if type(utterance) in self.history_utterances:\n",
    "                history.append(utterance)\n",
    "            if len(history) == self.history_length:\n",
    "                break\n",
    "\n",
    "        convo = \"\\n\".join(str(u) for u in history[::-1]) + \"\\n\"\n",
    "\n",
    "        response: Utterance = await self.run(\n",
    "            convo=convo,\n",
    "        )\n",
    "\n",
    "        response_origin = list(response.history())[-1]\n",
    "        response_origin.parent = utterance\n",
    "\n",
    "        if type(utterance) in utterances:\n",
    "            yield utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [KnowledgeSearchTool()]\n",
    "agent = StandardAgent(model_identifier=\"openai/babbage\", tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2618a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
